COMANDO PER PULIRE L'INPUT DI LEGEND (non utilizzato)
cat historical_stocks.csv | sed 's:\("\)\([^"]*\)\(,\)\([^"]*\):\2:g' > historical_stocks__cleaned.csv

COMANDO PER ESTRARRE I DATASET DI TEST
tail -n +2 historical_stock_prices.csv | shuf -n 100 -o stocks_test.csv

PRETTY-PRINT
column <filename> -t -s,

__________________________________________JOB 1 ___________________________________________________________________________

calculate the following values among all rows with same TICKER between 1998 and 2018:
- %INCREASE = difference(avg(CLOSE in 2018), avg(CLOSE in 1998))
- MIN_PRICE = min(LOW)
- MAX_PRICE = max(HIGH)
- AVG_VOL = avg(VOLUME)

goal: show the top 10 stocks (identified by TICKER) by their %INCREASE.
output: (TICKER, (%INCREASE, MIN_PRICE, MAX_PRICE, AVG_VOL))

strategy:
- map by TICKER but filter out every row out of the date period (ticker, details)
- reduce in the following way:
    input comes sorted by TICKER, so all rows with same TICKER are consecutive.
    to calculate %INCREASE, fill up two lists records_first_year and records_last_year containing CLOSE prices, 
      then calculate average values and subtract them
    initialize MIN_PRICE with LOW and MAX_PRICE with HIGH
    to calculate AVG_VOL, fill an empty list with VOLUMEs and calculate avg


__________________________________________JOB 2 ___________________________________________________________________________


historical_stocks.csv (legend):
(TICKER, EXCHANGE, NAME, SECTOR, INDUSTRY)

historical_stock_prices.csv (history): 
(TICKER, OPEN, CLOSE, ADJ_CLOSE, LOW, HIGH, VOLUME, DATE)
 0       1     2      3          4    5     6       7

OBIETTIVO: generare, per ciascun $SECTOR, il trend nel periodo 2004-2018, ovvero un elenco contenente, per ciascun YEAR
nell'intervallo: il volume complessivo del settore, la percentuale di variazione annuale (differenza percentuale arrotondata
tra la quotazione di fine anno e quella di inizio anno) e la quotazione giornaliera media.
volume e quotazione di un settore si ottengono sommando i relativi valori di tutte le azioni del settore.

for each SECTOR, for each YEAR: TOT_SECTOR_VOLUME, TOT_GROWTH, AVG_DAILY_PRICE
TOT_SECTOR_VOLUME = sum(VOLUME) of all rows with key (sector, year)
TOT_GROWTH = FINAL_PRICE - INITIAL_PRICE *100 / INITIAL_PRICE
             FINAL_PRICE = sum(CLOSING_PRICE) of all rows with key (sector, year) HAVING date = last date of year
             INITIAL_PRICE = sum(CLOSING_PRICE) of all rows with key (sector, year) HAVING date = first date of year
AVG_DAILY_PRICE = mean([sum(CLOSING_PRICE_DAY_1), sum(CLOSING_PRICE_DAY_2), ...])


Primo obiettivo: join. La chiave in comune è $TICKER. 

- Il mapper prende in input entrambi i file, e produce in output una tripla (TICKER, FLAG, VALUE).
  $FLAG serve a distinguere se la riga proviene dal primo o dal secondo file (0=legend, 1=history)
  $VALUE conterrà $SECTOR per le righe di legend e $DETAILS per le righe di history.
  $DETAILS è una lista che contiene nel seguente ordine: [$OPEN, $CLOSE, $LOW, $HIGH, $VOLUME, $DATE]
    N.B.: in questa fase vanno skippate le righe contenenti gli header dei due file, inoltre skippiamo anche le righe di
    history che non ricadono nel periodo temporale 2004-2018.
    
- Il reducer riceve righe raggruppate per TICKER.
  Per ciascun gruppo, la prima linea ha $FLAG=0. Da questa si estrae $TICKER e $SECTOR e passa alla prossima riga.
  Dalla seconda linea in poi $FLAG=1. A queste righe aggiunge $SECTOR a $DETAILS in ultima pos e stampa ($TICKER, $DETAILS)
  



sector1 year1
sector1 year2
...
sector1 yearN
sector2 year1
sector2 year2
...
sector2 yearN
...
sectorN yearN







INPUTDIR = Path(__file__).parent.parent.parent / "dataset"
STOCKS = INPUTDIR / "historical_stock_prices.csv"
LEGEND = INPUTDIR / "historical_stocks.csv"

if __name__ == '__main__':
    num_records_stocks = 20973890  # records in historical_stock_prices.csv
    num_records_legend = 6461  # records in historical_stocks.csv
    sample_size = 200

    skip = sorted(random.sample(range(num_records_stocks-1), num_records_stocks-1 - sample_size))
    df = pd.read_csv(STOCKS, skiprows=skip)

    p = 0.01
    df = pd.read_csv(str(STOCKS), header=0, skiprows=lambda i: i > 0 and random() > p)


